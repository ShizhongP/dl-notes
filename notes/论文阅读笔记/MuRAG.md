# EMNLP2022: MuRAG: Multimodal Retrieval-Augmented Generator for Open Question Answering over Images and Text

- [论文连接](https://arxiv.org/abs/2210.02928)
- 未公布代码
- 谷歌研究院（Wenhu Chen）
- arxiv 2022.10.6
- Emnlp2022 main
- cite: 89

## Kimi总结

这篇论文介绍了一个名为MuRAG（Multimodal Retrieval-Augmented Generator）的模型，它是为了解决开放域图像和文本上的问答问题而设计的。MuRAG通过结合大规模图像-文本和纯文本语料库进行预训练，使用联合对比和生成损失，以增强语言生成的能力。以下是论文的主要内容总结：

### 标题与作者

- **标题**: MuRAG: Multimodal Retrieval-Augmented Generator for Open Question Answering over Images and Text
- **作者**: Wenhu Chen, Hexiang Hu, Xi Chen, Pat Verga, William W. Cohen, Google Research

### 摘要

- MuRAG是一个多模态检索增强的生成器，能够通过访问外部非参数多模态记忆来增强语言生成。
- 该模型在WebQA和MultimodalQA两个数据集上进行了实验，结果显示MuRAG在两个数据集上都取得了最先进的准确性，超越了现有模型10-20%。

### 1. 引言

- 预训练语言模型如GPT-3和PaLM能够隐式地存储大量世界知识，但这些大型模型在编码罕见实体和事件的信息时常常失败，并且计算成本极高。
- 检索增强模型如REALM、RAG和RETRO通过利用外部非参数索引将世界知识融入语言生成，展示了在有限模型大小下的卓越性能。
- 然而，这些方法仅限于检索文本知识，忽略了图像等其他模态中包含的大量知识。

### 2. 相关工作

- 论文回顾了检索增强模型和多模态变换器的研究进展，并讨论了多模态问答的相关工作。

### 3. 模型

- MuRAG模型结合了预训练的T5和ViT模型构建了一个背骨编码器，用于编码图像-文本对、仅图像和仅文本输入到多模态表示。
- 在检索阶段，MuRAG接受任何模态的查询并从包含图像-文本对的记忆库中检索信息。
- 在阅读阶段，检索到的内容与查询结合，输入到背骨编码器中，生成文本输出。

### 4. 实验

- 论文在WebQA和MultimodalQA两个多模态问答数据集上评估了MuRAG的性能，并与现有的基线模型进行了比较。
- 实验结果表明，MuRAG在两个数据集上都取得了显著的性能提升。

### 5. 结论

- MuRAG是第一个能够在大规模语料库中检索多模态知识的视觉基础语言生成器，实验结果表明了这种方法的潜力。
- 尽管如此，对于需要对图像进行推理的知识寻求查询，MuRAG的性能仍然显著低于仅需要文本的查询，这表明还有很大的改进空间。

### 局限性

- MuRAG在预训练期间没有挖掘硬负例，导致需要较大的批量大小来收集足够硬的负例，这增加了预训练的计算资源需求。
- 预训练和微调的目标不一致，限制了模型性能。
- 视觉表示在阅读阶段相对昂贵，对于大型Top-K值的扩展提出了挑战。

### 伦理声明

- 论文使用了LAION数据集，并进行了自动过滤以减少有害内容，但由于数据集庞大，无法完全消除潜在风险。
- 模型可能包含种族、性别等偏见，作者在手动检查中观察到了一些这样的偏见。

这篇论文提出了一个创新的多模态检索增强模型，通过结合图像和文本信息来提升开放域问答任务的性能，并指出了未来研究的方向。
