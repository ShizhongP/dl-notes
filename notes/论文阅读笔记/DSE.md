# Unifying Multimodal Retrieval via Documents Screenshot Embedding (DSE)

- [论文连接](https://arxiv.org/abs/2406.11251)
- 代码会发布在 [代码](https://github.com/texttron/tevatron/)
- 单位: 滑铁卢大学
- 时间: 2024.6.17
- 状态: arxiv, 未有期刊和会议接收
- comments: 看起来好像是原本要投 ACL 的

## Kimi总结

这篇论文介绍了一种名为文档截图嵌入（Document Screenshot Embedding，简称DSE）的新型信息检索范式。DSE通过将文档截图作为统一的输入格式，避免了传统检索流程中对文档的解析和内容提取，从而保留了文档中的所有信息（如文本、图像和布局）。DSE利用大型视觉-语言模型直接将文档截图编码成密集的表示形式，以便于检索。

**主要贡献包括：**

1. 提出了DSE，一种新的文档检索方法，它将文档截图作为输入，不需要任何内容提取预处理，就能保留文档中的所有信息。

2. 构建了一个名为Wiki-SS的数据集，包含130万张维基百科网页截图，用于回答自然问题数据集中的问题。在这种文本密集型的文档检索设置中，DSE显示出与传统依赖于解析的文本检索方法相当的有效性。

3. 在混合模态任务（如幻灯片检索）中，DSE显著优于依赖OCR文本检索方法，例如在nDCG@10指标上超过15个百分点。

4. 论文还探讨了DSE在不同数据子集上的性能，并通过案例研究验证了DSE能够有效地从截图中捕获信息，增强检索能力。

**方法论：**

- DSE采用双编码器架构，其中文档截图和用户文本查询分别使用视觉和文本编码器编码成密集向量。
- 通过大型视觉-语言模型Phi-3-vision2处理截图，该模型可以处理更细粒度的信息，并可能增强语义理解。
- 使用对比学习进行训练，通过InfoNCE损失函数优化模型。

**实验设置：**

- 构建了Wiki-SS数据集，并使用自然问题数据集中的问题进行训练和评估。
- 在SlideVQA数据集上进行了开放域检索任务的实验，该任务要求模型从50k张幻灯片中检索相关幻灯片。

**实验结果：**

- 在Wiki-SS数据集上，DSE在top-1检索准确率上比BM25高出17个百分点。
- 在SlideVQA数据集上，DSE在nDCG@10和Recall@10指标上比基于OCR的文本检索方法高出超过15个百分点。

**结论：**

DSE作为一种新的信息检索范式，通过简化文档检索过程，绕过传统的预处理步骤，直接使用视觉-语言模型编码文档，为处理多样化的文档模态提供了统一的方法。实验结果表明，DSE在多种文档检索任务上优于传统检索器和基于OCR的方法，显示出DSE在多样化的实际应用中增强文档检索的潜力。未来的工作可以改进编码技术，并适应不同类型的文档，为多模态信息检索树立新的标准。

**限制：**

- DSE在更通用的文档检索任务中的有效性尚未得到充分验证，例如涉及PDF或具有高度变化结构和内容的网页。
- 当前方法仅依赖于监督微调，未来的研究可以探索对比预训练是否能够提高DSE的性能。
- 依赖视觉数据的方法在视觉数据质量较低的环境中可能面临挑战，模糊或低分辨率的截图可能会降低DSE的有效性。

## 阅读笔记

动机: 现有的RAG方法基于文本，需要对文档进行图像和文本的提取（特定的提取工具，使用OCR,多模态模型等）, 本文希望通过文档图像嵌入的方式来检索相关答案

方法:

1. 分别对文档图像和文本进行编码，使用对比学习的方法

结论:

1. 对比一些传统的文本RAG的方法有所提升（实验效果感觉也一般吧）
